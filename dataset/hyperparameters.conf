# Hyperparameters for simple_language_model_shakespeare
# Format: key=value
# Adjust values as needed based on the notebook / hardware.

# Model
model_type=transformer
n_layer=12
n_head=8
n_embd=768
dropout=0.1

# Data / tokenizer
dataset_path=data/shakespeare_char.txt
tokenizer=char
vocab_size=65
block_size=128        # context length (sequence length)

# Optimization / training
batch_size=128
learning_rate=3e-4
weight_decay=0.1
betas=0.9,0.95
grad_clip=1.0
max_iters=200000
lr_decay=true
warmup_iters=500

# Evaluation & checkpoints
eval_interval=1000
save_interval=5000
out_dir=out

# Misc
seed=1337
device=mps
# `compile_model` and `precision` removed â€” not required by the notebook